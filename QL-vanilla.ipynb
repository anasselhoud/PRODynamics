{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task:\n",
    "    def __init__(self, id, parts, CT, preced_list, forbid_list):\n",
    "        self.id = id\n",
    "        self.parts = parts\n",
    "        self.CT = CT\n",
    "        self.preced_list = preced_list\n",
    "        self.forbid_list = forbid_list\n",
    "        self.clusterTasksID = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "class QLearning:\n",
    "\n",
    "    def __init__(self, n_episodes, Tasks, targetCT, tolerance):\n",
    "        self.Tasks = Tasks\n",
    "        self.target = targetCT\n",
    "        self.tolerance = tolerance\n",
    "        self.solution = []\n",
    "        self.session_rewards = []\n",
    "        self.n_episodes = n_episodes\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        new_state = action\n",
    "        self.solution.append(new_state)\n",
    "\n",
    "        if len(self.solution) == len(self.Tasks):\n",
    "            done = True\n",
    "        return new_state, done\n",
    "\n",
    "    def split(self, a, n):\n",
    "        k, m = divmod(len(a), n)\n",
    "        return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n",
    "\n",
    "    def precedence_graph(self):\n",
    "        preced_graph = []\n",
    "\n",
    "        # No Precedence Restrictions\n",
    "        preced_graph.append([task for task in self.Tasks if not task.preced_list])\n",
    "        for task in self.Tasks:\n",
    "            # A precedence restriction with one of the first group\n",
    "            for preced_task in task.preced_list:\n",
    "                if preced_task in preced_graph:\n",
    "                    preced_graph.append(task)\n",
    "\n",
    "    def get_nworkstations(self):\n",
    "        total_ct = 0\n",
    "        ct_WS = [0]\n",
    "\n",
    "        for i in self.solution:\n",
    "          if ct_WS[-1]+float(self.Tasks[i].CT) > (1+self.tolerance)*(self.target / 2):\n",
    "            ct_WS.append(float(self.Tasks[i].CT))\n",
    "          else:\n",
    "            ct_WS[-1]+=float(self.Tasks[i].CT)\n",
    "\n",
    "        return len(ct_WS), ct_WS\n",
    "\n",
    "\n",
    "\n",
    "    def objectiveR2(self):\n",
    "        \"\"\"\n",
    "        Reward = -1 * (Number of Workstations Used) * (Number of Tasks Completed)\n",
    "        This reward function takes into account both the number of tasks completed and the number of workstations used up to\n",
    "        the current time. By multiplying the number of tasks completed with the negative of the number of workstations used,\n",
    "        the reward function encourages the agent to complete as many tasks as possible while minimizing the number of workstations\n",
    "        used.\n",
    "        The partial reward can be calculated at each step of the assembly process, after each task is completed. The agent can\n",
    "        then use this partial reward to update its policy and choose the next task to be completed based on the updated policy.\n",
    "\n",
    "        Note that this partial reward function assumes that all tasks have the same complexity and require the same amount of time and resources. If this is not the case, you may need to modify the reward function to take into account the specific characteristics of each task.\n",
    "        \"\"\"\n",
    "        if len(self.solution) == len(self.Tasks):\n",
    "          n, CTs = self.get_nworkstations()\n",
    "          m, CTsWorkers = self.estimate_WC()\n",
    "\n",
    "          cost_empty_workstation = -10 if n % 2 == 0 else 10\n",
    "\n",
    "          reward =-n*np.var(CTs)-m*np.var(CTsWorkers)-cost_empty_workstation\n",
    "          #reward =-n*np.var(CTs)-m*np.var(CTsWorkers)-cost_empty_workstation\n",
    "\n",
    "        else:\n",
    "          reward = -10000 #Sequence infeasible\n",
    "\n",
    "        #reward = (-n-n*np.std(CTs)-m*np.std(CTsWorkers)+self.cluster_reward()+self.check_precedence()+self.check_forbid())*len(self.solution)\n",
    "        #reward = (-n-m+self.cluster_reward()+self.check_forbid()+self.check_precedence()+cost_empty_workstation)*len(self.solution)\n",
    "        #reward = (-n-m+self.check_forbid())*len(self.solution)\n",
    "        return reward\n",
    "\n",
    "\n",
    "    def estimate_WC(self):\n",
    "        n_workers = 1\n",
    "        total_ct = 0\n",
    "        parts_done = []\n",
    "        ct_Workers = []\n",
    "        for i in self.solution:\n",
    "            total_ct += sum([float(part.duration) for part in self.Tasks[i].parts if part not in parts_done])\n",
    "            total_ct += sum([3 for part in self.Tasks[i].parts if part in parts_done])\n",
    "            for p in self.Tasks[i].parts:\n",
    "                parts_done.append(p)\n",
    "\n",
    "            if total_ct >= self.target:\n",
    "                n_workers += 1\n",
    "                ct_Workers.append(total_ct)\n",
    "                total_ct = 0\n",
    "        return n_workers, ct_Workers\n",
    "\n",
    "    def sequence_to_scenario(self, indiv):\n",
    "      Tasks_ID = [task.id for task in Tasks]\n",
    "\n",
    "      total_ct = 0\n",
    "      groups = []\n",
    "      group = []\n",
    "      for i in indiv:\n",
    "          total_ct += float(self.Tasks[i].CT)\n",
    "          group.append(i)\n",
    "          if total_ct >= (1+self.tolerance)*(self.target / 2):\n",
    "              groups.append(group.copy())\n",
    "              total_ct = 0\n",
    "              group=[]\n",
    "\n",
    "      if total_ct > 0:\n",
    "        if total_ct <= 0.3*(self.target / 2):\n",
    "          groups[-1] = groups[-1] + group\n",
    "        else:\n",
    "          groups.append(group.copy())\n",
    "\n",
    "      print(groups)\n",
    "      scenario = [0 for i in range(len(Tasks_ID))]\n",
    "      for i in range(len(groups)):\n",
    "        for j in groups[i]:\n",
    "          scenario[j] = i+1\n",
    "      return scenario\n",
    "\n",
    "    def sequence_to_scenario2(self, ant, final=False):\n",
    "      total_ct = 0\n",
    "      scenario = [0 for i in range(len(ant))]\n",
    "      n_workstations = 1\n",
    "      for i in ant:\n",
    "            total_ct += float(self.Tasks[i].CT)\n",
    "            if total_ct >= (self.target / 2):\n",
    "                n_workstations += 1\n",
    "                total_ct = 0\n",
    "            scenario[i] = n_workstations\n",
    "\n",
    "      return scenario\n",
    "\n",
    "    def update_feasible_actions(self, state, actions):\n",
    "        '''\n",
    "        The only restriction is that a certain node x is not allowed to be vis-ited unless all the predecessor nodes are visited prior to n.\n",
    "        '''\n",
    "\n",
    "        # We remove last action from the possible actions of next step\n",
    "        new_actions = list(actions).copy()\n",
    "\n",
    "        new_actions.remove(state)\n",
    "        # We add all new possible actions to it now (tasks that get now unlocked)\n",
    "        Tasks_ID = [task.id for task in self.Tasks]\n",
    "\n",
    "        new_unlocked = [self.Tasks.index(task) for task in self.Tasks if (\n",
    "                    all(Tasks_ID.index(item) in self.solution for item in task.preced_list) and self.Tasks.index(\n",
    "                task) not in self.solution and self.Tasks.index(task) not in new_actions)]\n",
    "        for task_ind in new_unlocked:\n",
    "            new_actions.append(task_ind)\n",
    "\n",
    "        return new_actions\n",
    "\n",
    "    def cluster_reward(self):\n",
    "\n",
    "      if self.solution[-1] in self.prefered_actions(self.solution[-2]) or self.solution[-2] in self.prefered_actions(self.solution[-1]):\n",
    "          return 100\n",
    "      else:\n",
    "        return -10\n",
    "\n",
    "    def get_feasible_actions(self, state):\n",
    "      new_actions = []\n",
    "      Tasks_ID = [task.id for task in Tasks]\n",
    "\n",
    "      new_unlocked = [self.Tasks.index(task) for task in self.Tasks if (\n",
    "                  all(Tasks_ID.index(item) in self.solution for item in task.preced_list) and (self.Tasks.index(task) not in self.solution))]\n",
    "      print(new_unlocked)\n",
    "      for task_ind in new_unlocked:\n",
    "          new_actions.append(task_ind)\n",
    "\n",
    "      return new_actions\n",
    "\n",
    "    def prefered_actions(self, state):\n",
    "      prefered_tasks = list(self.Tasks[state].clusterTasksID).copy()\n",
    "      return prefered_tasks\n",
    "\n",
    "    def get_prefered_actions(self, state):\n",
    "\n",
    "      prefered_tasks = list(self.Tasks[state].clusterTasksID).copy()\n",
    "      for ind in prefered_tasks:\n",
    "        if ind in self.solution:\n",
    "          prefered_tasks.remove(ind)\n",
    "\n",
    "\n",
    "      return prefered_tasks\n",
    "\n",
    "    def check_precedence(self):\n",
    "      Tasks_ID = [task.id for task in Tasks]\n",
    "      if self.Tasks[self.solution[-1]].preced_list != []:\n",
    "        if not all(Tasks_ID.index(item) in self.solution[:-1] for item in self.Tasks[self.solution[-1]].preced_list):\n",
    "\n",
    "          return -100\n",
    "        else:\n",
    "          return 100\n",
    "      else:\n",
    "        return 0\n",
    "\n",
    "    def check_forbid(self):\n",
    "      Tasks_ID = [task.id for task in Tasks]\n",
    "\n",
    "      total_ct = 0\n",
    "      groups = []\n",
    "      group = []\n",
    "      for i in self.solution:\n",
    "          total_ct += float(self.Tasks[i].CT)\n",
    "          group.append(i)\n",
    "          if total_ct >= (self.target / 2):\n",
    "              groups.append(group.copy())\n",
    "              total_ct = 0\n",
    "              group=[]\n",
    "\n",
    "      groups.append(group.copy())\n",
    "\n",
    "      if self.Tasks[self.solution[-1]].forbid_list != []:\n",
    "        for i in range(len(groups)):\n",
    "          if self.solution[-1] in groups[i]:\n",
    "            if all(Tasks_ID.index(item) not in groups[i] for item in self.Tasks[self.solution[-1]].forbid_list):\n",
    "              return 10\n",
    "            else:\n",
    "              return -10\n",
    "      else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "    def check_forbid_full(self, indiv):\n",
    "      Tasks_ID = [task.id for task in Tasks]\n",
    "\n",
    "      total_ct = 0\n",
    "      groups = []\n",
    "      group = []\n",
    "      for i in indiv:\n",
    "          total_ct += float(self.Tasks[i].CT)\n",
    "          group.append(i)\n",
    "          if total_ct >= (self.target / 2):\n",
    "              groups.append(group.copy())\n",
    "              total_ct = 0\n",
    "              group=[]\n",
    "\n",
    "      groups.append(group.copy())\n",
    "      j=0\n",
    "      for ind in indiv:\n",
    "        if self.Tasks[ind].forbid_list != []:\n",
    "          for i in range(len(groups)):\n",
    "            if ind in groups[i]:\n",
    "              if not all(Tasks_ID.index(item) not in groups[i] for item in self.Tasks[ind].forbid_list):\n",
    "                j+=1\n",
    "      return j\n",
    "\n",
    "    def check_precedence_full_sequence(self):\n",
    "      Tasks_ID = [task.id for task in Tasks]\n",
    "      j=0\n",
    "      for i in range(len(self.solution)-1):\n",
    "        if self.Tasks[self.solution[i+1]].preced_list != []:\n",
    "          if not all(Tasks_ID.index(item) in self.solution[:i+1] for item in self.Tasks[self.solution[i+1]].preced_list):\n",
    "            j+=1\n",
    "      return j\n",
    "\n",
    "    def check_precedence_final(self, candidate):\n",
    "      Tasks_ID = [task.id for task in Tasks]\n",
    "      j=0\n",
    "      for i in range(len(candidate)-1):\n",
    "        if self.Tasks[candidate[i+1]].preced_list != []:\n",
    "          if not all(Tasks_ID.index(item) in candidate[:i+1] for item in self.Tasks[candidate[i+1]].preced_list):\n",
    "            j+=1\n",
    "      return j\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, n_episodes=3000, exploration_prob=1, gamma=0.5, lr=0.001):\n",
    "\n",
    "        number_workstations_per_episode = []\n",
    "        exploration_decreasing_decay = 0.01\n",
    "        min_exploration_prob = 0.1\n",
    "        max_workstations = np.sum([float(t.CT) for t in self.Tasks])//self.target + 5\n",
    "        max_workers = max_workstations\n",
    "        actions = range(len(self.Tasks))\n",
    "        states = range(len(self.Tasks))\n",
    "\n",
    "        q_table = np.zeros((len(states), len(actions)))\n",
    "        reward = np.full((len(states), len(actions)), -1000)\n",
    "\n",
    "\n",
    "        pbar = tqdm(range(self.n_episodes), desc=\"QLearning\", colour='green')\n",
    "\n",
    "        reward_global = [0,0,0]\n",
    "        for e in pbar:\n",
    "            done = False\n",
    "            current_state = 0\n",
    "            self.solution = []\n",
    "\n",
    "            actions = [self.Tasks.index(task) for task in self.Tasks]\n",
    "            while not done:\n",
    "                if np.random.uniform(0, 1) < exploration_prob or e<0.2*self.n_episodes:\n",
    "                  action = random.choice(actions)\n",
    "                else:\n",
    "                  action = actions[np.argmax([q_table[current_state, i] for i in actions])]\n",
    "\n",
    "                next_state, done = self.step(action)\n",
    "                if len(self.solution) > 1:\n",
    "                  reward[self.solution[-2], self.solution[-1]] = reward[self.solution[-2], self.solution[-1]]+ self.cluster_reward() + self.check_precedence()\n",
    "                actions = self.update_feasible_actions(next_state, actions)\n",
    "\n",
    "                if actions == []:\n",
    "                  done = True\n",
    "\n",
    "                current_state = next_state\n",
    "\n",
    "            global_reward = self.objectiveR2()\n",
    "            for i, state_i in enumerate(self.solution):\n",
    "                if i < len(self.solution) - 1:\n",
    "                    reward[state_i, self.solution[i + 1]] = (reward[state_i, self.solution[i + 1]] + global_reward) / 2\n",
    "                    #reward[state_i, self.solution[i + 1]] = self.objectiveR2() - reward_global[0]/self.target - np.std(reward_global[1]) - np.std(reward_global[2])\n",
    "                    q_table[state_i, self.solution[i + 1]] = (1 - lr) * q_table[state_i, self.solution[i + 1]] + lr * (\n",
    "                                reward[state_i, self.solution[i + 1]] + gamma * max(q_table[:, self.solution[i + 1]]))\n",
    "\n",
    "            exploration_prob = max(min_exploration_prob, np.exp(-exploration_decreasing_decay * e))\n",
    "            pbar.set_postfix({\"Reward\": np.mean(reward)})\n",
    "            self.session_rewards.append(np.mean(reward))\n",
    "            number_workstations_per_episode.append(self.get_nworkstations()[0])\n",
    "\n",
    "\n",
    "        plt.plot(self.session_rewards)\n",
    "        plt.show()\n",
    "        done = False\n",
    "        current_state = 0\n",
    "\n",
    "        self.solution = []\n",
    "        #actions = self.update_feasible_actions(current_state, [self.Tasks.index(task) for task in self.Tasks if not task.preced_list])\n",
    "        actions = [self.Tasks.index(task) for task in self.Tasks]\n",
    "        while not done:\n",
    "            action = actions[np.argmax([q_table[current_state, a] for a in actions])]\n",
    "            next_state, done = self.step(action)\n",
    "            actions = self.update_feasible_actions(next_state, actions)\n",
    "            current_state = next_state\n",
    "\n",
    "        indiv = self.sequence_to_scenario(self.solution)\n",
    "\n",
    "        return indiv, 0, self.get_nworkstations()[0], 0"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
