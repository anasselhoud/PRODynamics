{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imporing required librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkJJOIdfSsmn",
        "outputId": "74f16be3-ac71-4d64-914f-5907ff003bc4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "max_length = 20\n",
        "\n",
        "\n",
        "color_pal = sns.color_palette()\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "csv_file_path = 'forecast_data 1.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Segmentation of Machines Idle Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_test = [eval(x) for x in df['Machines Idle Time'].tolist()]\n",
        "\n",
        "for i in range(max_length):\n",
        "    col_name = f'Machine_{i+1}_IT'\n",
        "    df[col_name] = [lst[i] if i < len(lst) else 0 for lst in list_test]\n",
        "\n",
        "df.drop(columns=['Machines Idle Time'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Segmentation of Machines CT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_test = [eval(x) for x in df['Machine CT'].tolist()]\n",
        "\n",
        "for i in range(max_length):\n",
        "    col_name = f'Machine_{i+1}_CT'\n",
        "    df[col_name] = [lst[i] if i < len(lst) else 0 for lst in list_test]\n",
        "\n",
        "df.drop(columns=['Machine CT'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Segmentation of Machines Breakdowns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_test = [eval(x) for x in df['Machines Breakdowns'].tolist()]\n",
        "\n",
        "for i in range(max_length):\n",
        "    col_name = f'Machine_{i+1}_BD'\n",
        "    df[col_name] = [lst[i] if i < len(lst) else 0 for lst in list_test]\n",
        "\n",
        "df.drop(columns=['Machines Breakdowns'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Segmentation of Buffers States"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_test = [eval(x) for x in df['Buffers State'].tolist()]\n",
        "\n",
        "simple_arrays = [[item for tup in inner_list for item in tup] for inner_list in list_test]\n",
        "\n",
        "for i in range(max_length*2):\n",
        "    buffer_number = (i // 2) + 1\n",
        "    buffer_subscript = \".1\" if i % 2 == 0 else \".2\"\n",
        "    col_name = f'Buff_{buffer_number}{buffer_subscript}_ST'\n",
        "    df[col_name] = [lst[i] if i < len(lst) else 0 for lst in simple_arrays]\n",
        "\n",
        "\n",
        "df.drop(columns=['Buffers State'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Segmentation of Machines State"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_test = [eval(x) for x in df['Machines State'].tolist()]\n",
        "modified_array = [[1 if element else 0 for element in row] for row in list_test]\n",
        "\n",
        "for i in range(max_length):\n",
        "    col_name = f'Machine_{i+1}_State'\n",
        "    df[col_name] = [lst[i] if i < len(lst) else 0 for lst in modified_array]\n",
        "\n",
        "df.drop(columns=['Machines State'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Segmentation of Robot State"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_list = [eval(x) for x in df['Robot State'].tolist()]\n",
        "\n",
        "\n",
        "df1 = pd.DataFrame(data_list, columns=['From', 'To'])\n",
        "\n",
        "elements = [f\"M{i}\" for i in range(1, 21)]\n",
        "\n",
        "df1_encoded = pd.DataFrame(0, columns=elements, index=df1.index)\n",
        "\n",
        "for index, row in df1.iterrows():\n",
        "    df1_encoded.loc[index, row['From']] = 1\n",
        "    df1_encoded.loc[index, row['To']] = 1\n",
        "\n",
        "df1_encoded['InputStock'] = df1_encoded['InputStock'].fillna(0).astype(int)\n",
        "df1_encoded['OutputStock'] = df1_encoded['OutputStock'].fillna(0).astype(int)\n",
        "\n",
        "df1.drop(['From', 'To'], axis=1, inplace=True)\n",
        "\n",
        "df1 = pd.concat([df1, df1_encoded], axis=1)\n",
        "\n",
        "df = df.join(df1)\n",
        "\n",
        "df.drop(columns=['Robot State'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding Machine Operating Time column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "columns = [f'Buffer {i} cap' for i in range(1, 21)] + [f'Machine {i} OperatingT' for i in range(1, 21)]\n",
        "data = np.zeros((343, 40))\n",
        "\n",
        "data[:, :7] = 1\n",
        "\n",
        "data[:, 20:27] = np.array([[100, 120, 200, 50, 20, 100, 50]])\n",
        "\n",
        "df2 = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "df =df.join(df2)\n",
        "\n",
        "#scaler = MinMaxScaler()\n",
        "\n",
        "#df_normalized_values = scaler.fit_transform(df.values)\n",
        "#df = pd.DataFrame(df_normalized_values, columns=df.columns, index=df.index)\n",
        "\n",
        "#df.drop(columns=['Sim Instant'], inplace=True)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculating Colsest Index to 1h of Sim Instant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "first_row_index = df[df['Sim Instant'] >= 3600].index.min()\n",
        "\n",
        "diff1 = abs(df.at[first_row_index, 'Sim Instant'] - 3600)\n",
        "diff2 = abs(df.at[first_row_index - 1, 'Sim Instant'] - 3600)\n",
        "\n",
        "closest_row_index = first_row_index if diff1 < diff2 else first_row_index - 1\n",
        "\n",
        "print(\"Index of the closest row to 3600:\", closest_row_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# step = closest_row_index + 1 \n",
        "# X = [[] for _ in range(182)]\n",
        "# y = []\n",
        "\n",
        "# for i in range(0, df.shape[0] - step):\n",
        "#     for j in range(182):\n",
        "#         X[j].append(df.iloc[i:i + step, j])\n",
        "#     y.append(df.iloc[i + step, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating the new dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_df = df.loc[:, 'Machine_1_IT':'Machine_20_IT']\n",
        "new_df = pd.concat([new_df, df.loc[:, 'M1':'M20']], axis=1)\n",
        "new_df = pd.concat([new_df, df[['InputStock', 'OutputStock']]], axis=1)\n",
        "new_df = pd.concat([new_df, df.loc[:, 'Buff_1.1_ST':'Buff_20.2_ST']], axis=1)\n",
        "\n",
        "new_df['Machine_IT_Total'] = new_df.loc[:, 'Machine_1_IT':'Machine_20_IT'].max(axis=1)\n",
        "\n",
        "new_df.drop(columns=new_df.loc[:, 'Machine_1_IT':'Machine_20_IT'].columns, inplace=True)\n",
        "new_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preparing the datya for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "steps = 1\n",
        "X = [[] for _ in range(63)]\n",
        "y = []\n",
        "\n",
        "for i in range(new_df.shape[0] - steps):\n",
        "    for j in range(63):\n",
        "        X[j].append(new_df.iloc[i:i + steps, j])\n",
        "    y.append(new_df.iloc[i + steps, 62])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = np.array(y)\n",
        "for i in range(len(X)):\n",
        "    X[i] = np.array(X[i])\n",
        "\n",
        "\n",
        "\n",
        "y=np.reshape(y, (len(y),1))\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.stack([X[i] for i in range(63)], axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test = X[:-42], X[-42:]\n",
        "y_train, y_test = y[:-42], y[-42:]\n",
        "X_train.shape[1], X_train.shape[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train[11]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "# set return requesnce = true, if we are going to have another LSTM layer\n",
        "model.add(LSTM(10, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(LSTM(10, return_sequences=False))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "filepath = 'models/{epoch:02d}-{loss:.4f}-{val_loss:.4f}-{mae:.4f}-{val_mae:.4f}.hdf5'\n",
        "\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=20),\n",
        "#              ModelCheckpoint(filepath, monitor='loss', save_best_only=True, mode='min')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer='ADAM', loss='mse', metrics=['mae'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Trainning the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, validation_split=0.2, epochs=1000, batch_size=1)\n",
        "#callbacks=callbacks,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MSE, MAE = model.evaluate(X_test, y_test)\n",
        "print(MSE, MAE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ploting the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(24,12))\n",
        "plt.plot(predictions)\n",
        "plt.plot(y_test)\n",
        "plt.legend(['Forecast', 'Actual'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print a desired row from the df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "desired_value = 300\n",
        "result_df = df.loc[df.index == desired_value]\n",
        "result_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Other random models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Assuming df is your DataFrame with normalized data\n",
        "\n",
        "# Convert the DataFrame to a numpy array\n",
        "data = df.values\n",
        "\n",
        "# Split the data into input (X) and output (y)\n",
        "X = data[:-1, :]  # All rows except the last one\n",
        "y = data[1:, :]   # All rows except the first one\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the data for LSTM input (samples, time steps, features)\n",
        "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(y_train.shape[1]))  # Output layer with the same number of features as y\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')  # You can use a different optimizer or loss function if needed\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "\n",
        "# Now you can use the trained model to predict the next row\n",
        "# For example, if you want to predict the next row after the last row in your training data:\n",
        "last_row = X_train[-1, :, :].reshape((1, 1, X_train.shape[2]))\n",
        "predicted_row = model.predict(last_row)\n",
        "\n",
        "\n",
        "# Assuming predicted_row is your numpy array\n",
        "predicted_df = pd.DataFrame(predicted_row.reshape((1, -1)))\n",
        "\n",
        "# Display the DataFrame\n",
        "predicted_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming df is your original DataFrame\n",
        "# Extract the actual values for Machine_1_T from the test set\n",
        "actual_values = y_test[:, df.columns.get_loc('Machine_1_IT')]\n",
        "\n",
        "# Predict the next values using the trained model\n",
        "predicted_values = model.predict(X_test)[:, df.columns.get_loc('Machine_1_IT')]\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "visualization_df = pd.DataFrame({'Actual': actual_values, 'Predicted': predicted_values})\n",
        "\n",
        "# Plot the actual vs predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(visualization_df['Actual'], label='Actual', marker='o')\n",
        "plt.plot(visualization_df['Predicted'], label='Predicted', marker='x')\n",
        "plt.title('Actual vs Predicted Values for Machine_1_IT')\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "predicted_values.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming predicted_row is your numpy array\n",
        "predicted_df = pd.DataFrame(predicted_row.reshape((1, -1)))\n",
        "\n",
        "# Display the DataFrame\n",
        "predicted_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have a DataFrame named 'df' with 182 columns and 343 rows\n",
        "\n",
        "# Creating a sample DataFrame for illustration\n",
        "# Replace this with your actual DataFrame\n",
        "data = np.random.randn(343, 182)\n",
        "df = pd.DataFrame(data, columns=[f'feature_{i}' for i in range(1, 183)])\n",
        "\n",
        "# Setting a sequence length (you can adjust this based on your requirements)\n",
        "seq_len = 10\n",
        "\n",
        "# Reshape the DataFrame into sequences\n",
        "num_sequences = len(df) // seq_len\n",
        "df_reshaped = df.iloc[:num_sequences * seq_len, :].values.reshape(num_sequences, seq_len, -1)\n",
        "\n",
        "# 'num_sequences' is the number of sequences, 'seq_len' is the length of each sequence,\n",
        "# and '-1' in the reshape means the remaining dimension is inferred based on the other dimensions.\n",
        "\n",
        "# Now 'df_reshaped' is a 3D tensor suitable for input into an LSTM\n",
        "print(\"Original DataFrame shape:\", df.shape)\n",
        "print(\"Reshaped DataFrame shape:\", df_reshaped.shape)\n",
        "df_reshaped"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
